---
title: "SVM"
author: "Cristopher Barrios, Carlos Daniel Estrada"
date: "2023-04-21"
output:
  html_document: default
  pdf_document: default
---
```{r message=FALSE, warning=FALSE}
library(e1071)
library(caret)
library(corrplot)
library(labelled)
library(plotly)
library(ggplot2)
```


### 1. Use los mismos conjuntos de entrenamiento y prueba de las hojas de trabajo pasadas para probar el algoritmo.
```{r}
set.seed(123)
train = read.csv("./train.csv")
```


### 2. Explore los datos y explique las transformaciones que debe hacerle para generar un modelo de máquinas vectoriales de soporte.
```{r  message=FALSE, warning=FALSE}

train[is.na(train)] <- 0
train$tipoDeCasa = as.numeric(as.character( cut(train$SalePrice,c(0,145000,205000,410000), labels = c(1, 2, 3))))
train[sapply(train, is.character)] <- lapply(train[sapply(train, is.character)],as.factor)

#columnas con NA
completeFun <- function(data, desiredCols) {
  completeVec <- complete.cases(data[, desiredCols])
  return(data[completeVec, ])
}
train <- completeFun(train, "tipoDeCasa") #variable respuesta, variable categorica 
str(train)
```

Las transformaciones realizadas son la eliminación de valores faltantes, la creación de una nueva variable categórica a partir de una variable numérica y la conversión de variables de tipo caracter en variables de tipo factor. Estas transformaciones son necesarias para que los datos sean adecuados para entrenar un modelo de SVM.

### 3. Use como variable respuesta la variable categórica que especifica si la casa es barata, media o cara
```{r}
train <- completeFun(train, "tipoDeCasa") #variable respuesta, variable categorica 

#datos con factor 
frstselect <- train[,c(2:5,8,9,11:43,46,49:54,56:62,64:72,76:80,82)]

#datos cuantitativos
scndselect <- subset (train, select = c(2,4,5,18,19,20,21,27,35,37,38,39,44,45,46,47,48,49,50,51,52,53,55,57,60,62,63,67,68,69,70,71,72,76,77,78,82))
scndselect[is.na(scndselect)] <- 0
```


### 4. Genere varios (más de 2) modelos de SVM con diferentes kernels y distintos valores en los parámetros c, gamma (circular) y d (en caso de que utilice el polinomial). Puede tunear el modelo de forma automática siempre que explique los resultados.

```{r  message=FALSE, warning=FALSE}

M <- cor(scndselect[,c(1:18)])
M1<- cor(scndselect[,c(19:37)])
M2<- cor(scndselect[,c(1:18)],scndselect[,c(19:37)])
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
```

```{r}
corrplot(M,  method = "color", col = col(200), order = "hclust", number.cex = .5,
         addCoef.col = "black",
         tl.col = "black",
         sig.level = 0.50, insig = "blank", 
         diag = FALSE)
```

```{r}
corrplot(M1,  method = "color", col = col(200), order = "hclust", number.cex = .5,
         addCoef.col = "black",
         tl.col = "black",
         sig.level = 0.50, insig = "blank", 
         diag = FALSE)
```

```{r message=FALSE, warning=FALSE}
corrplot(M2,  method = "color", col = col(200), order = "hclust", number.cex = .5,
         addCoef.col = "black",
         tl.col = "black",
         sig.level = 0.50, insig = "blank", 
         diag = TRUE)
```

Se realizó una matriz de correlación entre las variables de los dos conjuntos de datos (frstselect y scndselect) y entre ambos conjuntos. La función corrplot se utilizó para visualizar las matrices de correlación en diferentes colores.

```{r}
tipocor<- cor(scndselect[,-1],scndselect$tipoDeCasa)
tipocor
```

Se calculó la correlación entre todas las variables de scndselect y la variable "tipoDeCasa".

```{r}
porciento <- 70/100

#todo tipo de variables 
trainRowsNumber<-sample(1:nrow(frstselect),porciento*nrow(frstselect))
train<-frstselect[trainRowsNumber,]
test<-frstselect[-trainRowsNumber,]

#variables cuantitativas
trainRowsNum<-sample(1:nrow(scndselect),porciento*nrow(scndselect))
train1<-scndselect[trainRowsNum,]
test1<-scndselect[-trainRowsNum,]

#Modelos
modeloSVM_L1<-svm(tipoDeCasa~., data=train,type="C-classification", cost=2^5, kernel="linear") 
modeloSVM_L2<-svm(tipoDeCasa~., data=train,type="C-classification", cost=0.5, kernel="linear")
modeloSVM_L3<-svm(tipoDeCasa~., data=train,type="C-classification", cost=2^-5, kernel="linear")


modeloSVM_R1<-svm(tipoDeCasa~., data=train,type="C-classification", gamma=0.005,kernel="radial")
modeloSVM_R2<-svm(tipoDeCasa~., data=train,type="C-classification", gamma=0.05,kernel="radial")
modeloSVM_R3<-svm(tipoDeCasa~., data=train,type="C-classification", gamma=2^-5,kernel="radial")


modeloSVM_P1<-svm(tipoDeCasa~., data=train,type="C-classification", gamma=1, kernel="polynomial", coef0=1, degree= 8) 
modeloSVM_P2<-svm(tipoDeCasa~., data=train,type="C-classification", gamma=5, kernel="polynomial", coef0=1)
modeloSVM_P3<-svm(tipoDeCasa~., data=train,type="C-classification", gamma=2^-5, kernel="polynomial", coef0=1)
```

Se dividió el conjunto de datos en dos grupos: un conjunto de entrenamiento (train) y un conjunto de prueba (test). Se crearon varios modelos de SVM con diferentes kernels (lineal, radial y polinómico) y diferentes valores de los parámetros c, gamma y d.

```{r}
summary(modeloSVM_L1)
```
Este resumen muestra que el modelo SVM lineal con un costo de 32 tiene 337 vectores de soporte, y que el número de clases es 3. Además, se proporcionan las frecuencias de los vectores de soporte en cada clase.

```{r}
summary(modeloSVM_R1)
```
El modelo SVM radial con un parámetro gamma de 0.005 y un costo de 1 tiene 641 vectores de soporte, y que el número de clases es 3. También se proporcionan las frecuencias de los vectores de soporte en cada clase.
```{r}
summary(modeloSVM_P1)
```
El modelo SVM polinomial con un parámetro gamma de 1, un coeficiente de término independiente de 1 y un grado de 8 tiene 308 vectores de soporte, y que el número de clases es 3. También se proporcionan las frecuencias de los vectores de soporte en cada clase.


### 5. Use los modelos para predecir el valor de la variable respuesta
```{r}
# Linear
process_timeL1 <- proc.time()
prediccionL1<-predict(modeloSVM_L1,newdata=test[,1:67])
process_timeL1 <- proc.time() - process_timeL1
process_timeL2 <- proc.time()
prediccionL2<-predict(modeloSVM_L2,newdata=test[,1:67])
process_timeL2 <- proc.time() - process_timeL2
process_timeL3 <- proc.time()
prediccionL3<-predict(modeloSVM_L3,newdata=test[,1:67])
process_timeL3 <- proc.time() - process_timeL3
process_timeL_avarage <- (process_timeL1[3] + process_timeL2[3] + process_timeL3[3])/3

# Radial
process_timeR1 <- proc.time()
prediccionR1<-predict(modeloSVM_R1,newdata=test[,1:67])#[,1:37]
process_timeR1 <- proc.time() - process_timeR1
process_timeR2 <- proc.time()
prediccionR2<-predict(modeloSVM_R2,newdata=test[,1:67])#[,1:37]
process_timeR2 <- proc.time() - process_timeR2
process_timeR3 <- proc.time()
prediccionR3<-predict(modeloSVM_R3,newdata=test[,1:67])#[,1:37]
process_timeR3 <- proc.time() - process_timeR3
process_timeR_avarage <- (process_timeR1[3] + process_timeR2[3] + process_timeR3[3])/3

# Polinomial
process_timeP1 <- proc.time()
prediccionP1<-predict(modeloSVM_P1,newdata=test[,1:67])
process_timeP1 <- proc.time() - process_timeP1
process_timeP2 <- proc.time()
prediccionP2<-predict(modeloSVM_P2,newdata=test[,1:67])
process_timeP2 <- proc.time() - process_timeP2
process_timeP3 <- proc.time()
prediccionP3<-predict(modeloSVM_P3,newdata=test[,1:67])
process_timeP3 <- proc.time() - process_timeP3
process_timeP_avarage <- (process_timeP1[3] + process_timeP2[3] + process_timeP3[3])/3

#Cambio de tipo de data a factors
test$tipoDeCasa<- as.factor(test$tipoDeCasa)
test1$tipoDeCasa<- as.factor(test$tipoDeCasa)
```

Se ajusta tres tipos de modelos SVM: lineal, radial y polinomial. Luego, cada modelo se utiliza para hacer predicciones en el conjunto de datos de prueba almacenado en la variable test utilizando la función predict. Los resultados de cada modelo se almacenan en variables distintas

### 6. Haga las matrices de confusión respectivas.
```{r}
#linear
cmL1<-confusionMatrix(test$tipoDeCasa,prediccionL1)
cmL2<-confusionMatrix(test$tipoDeCasa,prediccionL2)
cmL3<-confusionMatrix(test$tipoDeCasa,prediccionL3)
```

```{r}
#linear
cmL1
```

Muestra que de las 162 casas de tipo 1, 128 fueron correctamente clasificadas, mientras que 29 se clasificaron erróneamente como tipo 2 y 1 como tipo 3. De las 150 casas de tipo 2, 104 se clasificaron correctamente, mientras que 24 y 22 se clasificaron erróneamente como tipo 1 y tipo 3, respectivamente. De las 122 casas de tipo 3, 89 se clasificaron correctamente, mientras que 1 y 33 se clasificaron erróneamente como tipo 1 y tipo 2, respectivamente.

```{r}
#linear
cmL2
```
Muestra que de las 162 casas de tipo 1, 140 fueron correctamente clasificadas, mientras que 18 se clasificaron erróneamente como tipo 2. De las 150 casas de tipo 2, 106 se clasificaron correctamente, mientras que 22 y 24 se clasificaron erróneamente como tipo 1 y tipo 3, respectivamente. De las 122 casas de tipo 3, 98 se clasificaron correctamente, mientras que 1 y 23 se clasificaron erróneamente como tipo 1 y tipo 2, respectivamente.


```{r}
#linear
cmL3
```

Muestra que de las 162 casas de tipo 1, 147 fueron correctamente clasificadas, mientras que 11 se clasificaron erróneamente como tipo 2. De las 150 casas de tipo 2, 115 se clasificaron correctamente, mientras que 19 y 23 se clasificaron erróneamente como tipo 1 y tipo 3, respectivamente. De las 122 casas de tipo 3, 100 se clasificaron correctamente, mientras que ninguna se clasificó erróneamente como tipo 1 o tipo 2.

```{r}
#radial
cmR1<-confusionMatrix(test$tipoDeCasa,prediccionR1)
cmR2<-confusionMatrix(test$tipoDeCasa,prediccionR2)
cmR3<-confusionMatrix(test$tipoDeCasa,prediccionR3)
```

```{r}
#radial
cmR1
```

Este modelo tuvo una precisión general del 82,6%. Predijo correctamente la clase 1 en el 86,13% de los casos, la clase 2 en el 74,05% de los casos y la clase 3 en el 90% de los casos. También tuvo una sensibilidad y especificidad alta en todas las clases, lo que significa que el modelo pudo distinguir correctamente entre las diferentes clases.

```{r}
#radial
cmR2
```

Tuvo una precisión general del 80,28%. Predijo correctamente la clase 1 en el 85,12% de los casos, la clase 2 en el 69,59% de los casos y la clase 3 en el 91,3% de los casos. También tuvo una alta sensibilidad en todas las clases, pero su especificidad fue menor en la clase 2, lo que indica que el modelo tuvo dificultades para distinguir entre la clase 2 y otras clases.

```{r}
#radial
cmR3
```
Tuvo una precisión general del 83,29%. Predijo correctamente la clase 1 en el 88,41% de los casos, la clase 2 en el 73,49% de los casos y la clase 3 en el 91,09% de los casos. También tuvo una alta sensibilidad y especificidad en todas las clases, lo que indica que el modelo pudo distinguir correctamente entre las diferentes clases.

```{r}
# Polinomial
cmP1<-confusionMatrix(test$tipoDeCasa,prediccionP1)
cmP2<-confusionMatrix(test$tipoDeCasa,prediccionP2)
cmP3<-confusionMatrix(test$tipoDeCasa,prediccionP3)

```

```{r}
# Polinomial
cmP1
```

```{r}
# Polinomial
cmP2

```

```{r}
# Polinomial
cmP3
```

Los resultados de las matrices de confusión indican que los modelos polinomiales tuvieron un buen desempeño en la clasificación de los tipos de casas. La matriz de confusión cmP1 muestra que el modelo tuvo una precisión general del 79,12%, con una sensibilidad del 85,80% para la clase 1 (casas), 67,04% para la clase 2 (apartamentos) y 91,57% para la clase 3 (condominios). La matriz de confusión cmP2 muestra que el modelo tuvo una precisión general del 81,44%, con una sensibilidad del 86,14% para la clase 1, 73,97% para la clase 2 y 84,03% para la clase 3. La matriz de confusión cmP3 muestra que el modelo tuvo una precisión general del 82,13%, con una sensibilidad del 86,96% para la clase 1, 74,50% para la clase 2 y 85,12% para la clase 3.






### 7. Analice si los modelos están sobreajustados o desajustados. ¿Qué puede hacer para manejar el sobreajuste o desajuste?

Básicamente, se sugiere la utilización de la técnica de validación cruzada para evitar el sobreajuste o desajuste en los modelos, lo que permite evaluar los resultados y examinar las independencias en los subconjuntos. En el caso específico de SVM, es posible combatir el subajuste mediante la adición de características de entrenamiento y la optimización de los valores del núcleo para mejorar el ajuste del modelo.
 
### 8. Compare los resultados obtenidos con los diferentes modelos que hizo en cuanto a efectividad, tiempo de procesamiento y equivocaciones (donde el algoritmo se equivocó más, donde se equivocó menos y la importancia que tienen los errores).
```{r}
#accuracy
cmL1<-cmL1$overall[['Accuracy']]*100
cmL2<-cmL2$overall[['Accuracy']]*100
cmL3<-cmL3$overall[['Accuracy']]*100
cmR1<-cmR1$overall[['Accuracy']]*100
cmR2<-cmR2$overall[['Accuracy']]*100
cmR3<-cmR3$overall[['Accuracy']]*100
cmP1<-cmP1$overall[['Accuracy']]*100
cmP2<-cmP2$overall[['Accuracy']]*100
cmP3<-cmP3$overall[['Accuracy']]*100

accuracycm1<- c(cmL1,cmR1,cmP1)
accuracycm2<- c(cmL2,cmR2,cmP2)
accuracycm3<- c(cmL3,cmR3,cmP3)

tiposvmcm<- c("linear","radial","polinomial")

accuracycm4<- c(cmL1,cmL2,cmL3)
accuracycm5<- c(cmR1,cmR2,cmR3)
accuracycm6<- c(cmP1,cmP2,cmP3)

data <- data.frame(tiposvmcm, accuracycm1, accuracycm2, accuracycm3)
```

```{r}
fig <- plot_ly(data, x = ~tiposvmcm, y = ~accuracycm1, type = 'bar',text = paste(signif(accuracycm1,digits = 3),"%"), textposition = 'auto', name = '')
fig <- fig %>% add_trace(y = ~accuracycm2, name = '',text = paste(signif(accuracycm2,digits = 3),"%"), textposition = 'auto')
fig <- fig %>% add_trace(y = ~accuracycm3, name = '',text = paste(signif(accuracycm3,digits = 3),"%"), textposition = 'auto')
fig <- fig %>% layout(title="(Accuracy vs kernel type) of SVM",yaxis = list(title = 'Accuracy(%)'),xaxis = list(title = 'kernel'), barmode = 'group')
fig
```


### 9. Compare la eficiencia del mejor modelo de SVM con los resultados obtenidos en los algoritmos de las hojas de trabajo anteriores que usen la misma variable respuesta (árbol de decisión y random forest, naive bayes). ¿Cuál es mejor para predecir? ¿Cuál se demoró más en procesar?
```{r}
modelos_aplicados <- c("Arbol de Clasificacion","Naive Bayes","Regresion Lineal", "SVM")
accuracy_individual <- c(73.61, 76.69, 70.05, 83.99)
comparacion_modelos <- data.frame(modelos_aplicados, accuracy_individual)
fig_2 <- plot_ly(comparacion_modelos, x = ~modelos_aplicados, y = ~accuracy_individual, type = 'bar', text = paste(signif(accuracy_individual,digits = 3),"%"), textposition = 'auto', name = '')
fig_2 <- fig_2 %>% layout(title="Accuracy vs Modelo Aplicado",yaxis = list(title = 'Accuracy(%)'),xaxis = list(title = 'Modelo Aplicado'), barmode = 'group')
fig_2
```

```{r}
modelos_SVM <- c("Lineal", "Radial", "Polinomial")
elapsed <- c(process_timeL_avarage, process_timeR_avarage, process_timeP_avarage)
comparacion_elapsed <- data.frame(modelos_SVM, elapsed)
fig_3 <- plot_ly(comparacion_elapsed, x = ~modelos_SVM, y = ~elapsed, type = 'bar', text = paste(signif(elapsed,digits = 3),"s"), textposition = 'auto', name = '')
fig_3<- fig_3 %>% layout(title="Tiempo de Ejecucion vs Modelo Aplicado",yaxis = list(title = 'Time(s)'),xaxis = list(title = 'Modelo Aplicado'), barmode = 'group')
fig_3
```


### 10. Genere un buen modelo de regresión, use para esto la variable del precio de la casa directamente.

### 11. Compare los resultados del modelo de regresión generado con los de hojas anteriores que utilicen la misma variable, como la de regresión lineal.

### 12. Genere un informe de los resultados y las explicaciones.

Luego de comparar varios modelos de Support Vector Machine, se puede observar que el modelo lineal obtuvo el mayor índice de precisión con un 84%, seguido del modelo radial con un 83.3% y otro modelo radial con un 82.6%. Aunque el modelo con el índice de precisión más bajo aún alcanzó un 74.5%, lo que es considerado un índice de precisión destacable. A pesar de esto, no se puede determinar cuál modelo es el mejor, pero se puede concluir que el modelo lineal fue el que arrojó los mejores resultados, muy similares a los modelos polinomial y radial. Además, este modelo fue el que tuvo el menor tiempo de ejecución, seguido del modelo polinomial y en último lugar el modelo radial. Es decir, el modelo más eficiente fue el que tuvo el menor tiempo de ejecución. En comparación con otros modelos trabajados anteriormente, en esta hoja de trabajo se lograron los índices de precisión más altos. Sin embargo, para determinar el modelo más eficiente se deberían considerar más variables que influyen en el resultado de cada modelo, y esto requeriría más tiempo y conocimiento.

En relación al modelo de clasificación y regresión lineal, se obtuvo una menor tasa de efectividad que con el modelo Naive Bayes y, por último, con el modelo SVM. Las principales diferencias entre cada uno de los modelos están en las matrices de confusión. En el caso del modelo de regresión lineal, se observaron más errores en la precisión de casas caras.

En cuanto al modelo de árbol de clasificación, se obtuvo una menor cantidad de errores en el tipo de casa caro, lo que se reflejó en la gráfica anterior. Sin embargo, el modelo Naive Bayes sigue proporcionando una menor tasa de errores y una mejor aproximación. La principal diferencia entre estos modelos y SVM radica en que el promedio entre los primeros es de 73.44% en comparación con el 84% que proporciona SVM, lo que representa una diferencia de aproximadamente el 10%. Esto indica que SVM proporciona una mayor certeza para este conjunto de datos.

En cuanto a los tiempos de ejecución de cada modelo SVM, se observó que el modelo lineal es el más eficiente, seguido del modelo polinomial y, por último, el modelo radial. Es importante tener en cuenta que si la capacidad de procesamiento de la computadora se ve afectada por otra tarea, esto puede afectar la eficiencia de los diferentes tipos de kernel del modelo y cambiar la gráfica de comparación de tiempos de ejecución de manera considerable.

Al comparar los diferentes modelos de Support Vector Machine (SVM) en esta hoja de trabajo, se puede concluir que el modelo lineal obtuvo los mejores resultados en cuanto a precisión y tiempo de ejecución. Aunque los modelos polinomial y radial también mostraron resultados similares, el lineal fue el más eficiente y preciso. Asimismo, es importante tener en cuenta que la elección del modelo adecuado depende de la naturaleza de los datos y del problema a resolver. Es fundamental tener un conocimiento profundo de cada modelo y de sus variables para determinar cuál es el más adecuado en cada situación.